# Variational Laplace for Dummies

If you are reading this book, you are interested in understanding what variational Laplace is, how it is used to do Bayesian statistics, how it relates to neuroscience, active inference, predictive processing, or something along these lines. If you are like me and have very little knowledge in mathematics, you may have encountered many papers that try to explain variational Laplace and felt intimidated by it. That is not to say that people did a bad job at explaining it in existing text books and papers, there are great resources out there. However, most of these resources require the reader to be already familiar with quite advanced mathematical concepts. This notebook was created to be maximally accessible. I wrote this notebook as I was reading Peter Zeidman's "A primer on variational Laplace", and it is me explaining myself the bits of maths I was missing.

I will start by introducing Bayesian statistics using very simple example. I will build from very simple intuition that I believe we all share to introduce mathematical formalism and show how that helps us go beyond our simple intuition. I will show how Bayes theorem aims at reaching the best possible conclusion based on data when we are dealing with uncertainty.

I will then proceed to show that while the Bayes Theorem (which is a single equation) is really helpful, it can in most cases not solvable analytically. This means that we can't solve the equation by hand to then be able to plug in the values that we have to get the answer to our question. And even more unfortunately, for most interesting questions we try to answer with statistics (the weight of a regressor in a linear regression for example), computational solutions are also not feasible. This means that we can't try a bunch of options with a computer to find something that comes close to a solution, because there are way too many things we can try, and we would need to let our computer run for decades to get answers to even simple problems. Don't worry if this all sounds a bit confusing right now. The point is that while Bayes Theorem can tell us which is the best conclusion to reach based on some data, we very often can't get that answer straight away, because the maths required to do so are too complicated or simply impossible.

Following a detailed explanation illustrated with simple example as to why we cannot in most cases solve the Bayesian theorem, I will show that we can instead find mathematical tricks to solve something else. That something else should get us an answer that is close enough to what we would have gotten if we had actually solved the Bayes theorem. Even better, we can know that the larger that value gets, the closest we are approaching the answer the Bayes theorem would have given us. This means that we can strive to always get higher values to get a more accurate answer, and you will see then why that is a good thing. This quantity that we will seek to compute is the so called Free Energy. In order to compute this quantity, we need to use a lot of mathematical tricks to make impossible equations possible, and these series of tricks is what is referred to as Variational Laplace.

Hopefully, once we are done with all of this, you should have a good understanding of how Variational Laplace works. At least that's how it worked for me.

```{tableofcontents}
```
